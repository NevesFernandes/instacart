{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c64bee-63d2-41df-a169-c15c73fc62fa",
   "metadata": {},
   "source": [
    "# Task - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf79af-9091-48a2-b8cc-4841b7298871",
   "metadata": {},
   "source": [
    "### Step 3 - Import your analysis libraries, as well as your new customer data set as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa5599e-930c-4eca-9c6c-7427c459549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt #this is to specifically handle with date_joined object and look at it as a date!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a306a3-d15c-42b9-8a44-5694cf20f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up path variables\n",
    "data_path = r'../2_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95080939-fec0-4945-9679-1dd74ca36be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing most recent pickle file into working dataframe\n",
    "df_customers = pd.read_csv(os.path.join(data_path, '1_Original_Data', 'customers.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1c1d5d-7248-491e-b68f-02c61ac82a7a",
   "metadata": {},
   "source": [
    "### Step 4 - Wrangle the data so that it follows consistent logic; for example, rename columns with illogical names and drop columns that don’t add anything to your analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5978d860-df14-4851-a1f2-253901d82bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       206209 non-null  int64 \n",
      " 1   First Name    194950 non-null  object\n",
      " 2   Surnam        206209 non-null  object\n",
      " 3   Gender        206209 non-null  object\n",
      " 4   STATE         206209 non-null  object\n",
      " 5   Age           206209 non-null  int64 \n",
      " 6   date_joined   206209 non-null  object\n",
      " 7   n_dependants  206209 non-null  int64 \n",
      " 8   fam_status    206209 non-null  object\n",
      " 9   income        206209 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969c5ff7-aa57-48c1-b554-fd89023f5737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Surnam</th>\n",
       "      <th>Gender</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>n_dependants</th>\n",
       "      <th>fam_status</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26711</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>Esquivel</td>\n",
       "      <td>Female</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>48</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>165665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33890</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>Hart</td>\n",
       "      <td>Female</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>36</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>59285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65803</td>\n",
       "      <td>Kenneth</td>\n",
       "      <td>Farley</td>\n",
       "      <td>Male</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>35</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>married</td>\n",
       "      <td>99568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125935</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>Hicks</td>\n",
       "      <td>Female</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>40</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>42049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130797</td>\n",
       "      <td>Ann</td>\n",
       "      <td>Gilmore</td>\n",
       "      <td>Female</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>26</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>40374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id First Name    Surnam  Gender       STATE  Age date_joined  \\\n",
       "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
       "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
       "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
       "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
       "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
       "\n",
       "   n_dependants fam_status  income  \n",
       "0             3    married  165665  \n",
       "1             0     single   59285  \n",
       "2             2    married   99568  \n",
       "3             0     single   42049  \n",
       "4             1    married   40374  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec5158-136e-4971-b12c-3a39dec95222",
   "metadata": {},
   "source": [
    "Looking at the fields, I've decided to:\n",
    "* Drop the columns with the client names. It's a sensitive ethical issue, especially because there is extra personal info regarding dependants, family status, income, etc. Statistics will only be produced in aggregation. The user_id, however, shall remain because it will be the key to combine with orders dataset.\n",
    "* Rename fields that use Capital letters to all minor letters, to make it uniform during programming. In the final stage of reporting, I can always re-label for something prettier\n",
    "* rename `n_dependants` and `fam_status` to more meaningful names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59261cc3-e6ac-4740-90c4-0a59c2a12ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unneeded fields\n",
    "df_customers.drop(labels=['First Name','Surnam'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413d6d9b-efed-4871-8449-c8ec1ecb0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming fields\n",
    "df_customers.rename(columns = {'Gender' : 'gender', 'STATE' : 'state', 'Age' : 'age', 'n_dependants' : 'number_of_dependants', 'fam_status' : 'family_status'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67362689-6ca7-4d85-80d4-e9c8063e4c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   user_id               206209 non-null  int64 \n",
      " 1   gender                206209 non-null  object\n",
      " 2   state                 206209 non-null  object\n",
      " 3   age                   206209 non-null  int64 \n",
      " 4   date_joined           206209 non-null  object\n",
      " 5   number_of_dependants  206209 non-null  int64 \n",
      " 6   family_status         206209 non-null  object\n",
      " 7   income                206209 non-null  int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48eb1e4-3b7b-4feb-b105-c32857e1e096",
   "metadata": {},
   "source": [
    "### Step 5 - Complete the fundamental data quality and consistency checks you’ve learned throughout this Achievement; for example, check for and address missing values and duplicates, and convert any mixed-type data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5b419-04a2-4edb-9579-6746981b828a",
   "metadata": {},
   "source": [
    "##### 5.1 - Main verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d73ef5-d1e1-4921-b948-16a8bdc7b332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>number_of_dependants</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>103105.000000</td>\n",
       "      <td>49.501646</td>\n",
       "      <td>1.499823</td>\n",
       "      <td>94632.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59527.555167</td>\n",
       "      <td>18.480962</td>\n",
       "      <td>1.118433</td>\n",
       "      <td>42473.786988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51553.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59874.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>103105.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>154657.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>124244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>206209.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>593901.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id            age  number_of_dependants         income\n",
       "count  206209.000000  206209.000000         206209.000000  206209.000000\n",
       "mean   103105.000000      49.501646              1.499823   94632.852548\n",
       "std     59527.555167      18.480962              1.118433   42473.786988\n",
       "min         1.000000      18.000000              0.000000   25903.000000\n",
       "25%     51553.000000      33.000000              0.000000   59874.000000\n",
       "50%    103105.000000      49.000000              1.000000   93547.000000\n",
       "75%    154657.000000      66.000000              3.000000  124244.000000\n",
       "max    206209.000000      81.000000              3.000000  593901.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary statistics for numeric fields\n",
    "df_customers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc55fe-1e05-4376-9d70-005171ed76ae",
   "metadata": {},
   "source": [
    "1. **user_id** all statistics match the expected, the count is the same value as we had from orders df as unique user_ids, the mean is exactly in the middle of the observations and equal to the median (Q50)\n",
    "1. **age** it makes sense the min to be 18, most likely is the legal age for a person to be instcart customer. Nothing seems wrong in the remaining statistics\n",
    "2. **number_of_dependants** all the statistics here make sense as well. At most 3 dependants, an average matching a value well in the middle of the range (0,3). I'll run some value_counts ahead to check more things\n",
    "3. **income** the max value looks odd, especially when we see that it's super far away from quartiles evolution, and that mean and median are close to each other, not showing signs of skewness. deserves more investigation. In particular I'll check for values beyond 1.5 times the IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdc9b70d-915e-43b8-a1a7-7445a04bd172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns with mixed datatypes found\n"
     ]
    }
   ],
   "source": [
    "#checking for columns with mixed datatypes\n",
    "col_with_mixed_types = False\n",
    "for col in df_customers.columns.tolist():\n",
    "  weird = (df_customers[[col]].map(type) != df_customers[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_customers[weird]) > 0:\n",
    "    print (col)\n",
    "    col_with_mixed_types = True\n",
    "if (not col_with_mixed_types):\n",
    "  print('No columns with mixed datatypes found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24795f13-04de-4e8b-b4a7-210f08a48d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                 0\n",
       "gender                  0\n",
       "state                   0\n",
       "age                     0\n",
       "date_joined             0\n",
       "number_of_dependants    0\n",
       "family_status           0\n",
       "income                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if there are null values to be addressed\n",
    "df_customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e3cab-b009-462c-959d-be47ed72e834",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "I already knew this from the summary provided by <code>df_customers.info()</code></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ed02134-2595-4eda-a9e9-db6f8db14974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>number_of_dependants</th>\n",
       "      <th>family_status</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, gender, state, age, date_joined, number_of_dependants, family_status, income]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicates\n",
    "df_dup_customers = df_customers[df_customers.duplicated()]\n",
    "df_dup_customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f386c61-3cc4-4fa8-b9e0-bb525a1efb37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "No duplicates found\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de034e18-4786-45a0-a647-b87a1506486e",
   "metadata": {},
   "source": [
    "##### 5.2 - Additional consistency checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013af842-f3ed-4277-a430-c2422990ec70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family_status\n",
       "married                             144906\n",
       "single                               33962\n",
       "divorced/widowed                     17640\n",
       "living with parents and siblings      9701\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers['family_status'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e77ec42-a0b9-4c53-ba9f-190914aa3884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Florida                 4044\n",
       "Colorado                4044\n",
       "Illinois                4044\n",
       "Alabama                 4044\n",
       "District of Columbia    4044\n",
       "Hawaii                  4044\n",
       "Arizona                 4044\n",
       "Connecticut             4044\n",
       "California              4044\n",
       "Indiana                 4044\n",
       "Arkansas                4044\n",
       "Alaska                  4044\n",
       "Delaware                4044\n",
       "Iowa                    4044\n",
       "Idaho                   4044\n",
       "Georgia                 4044\n",
       "Wyoming                 4043\n",
       "Mississippi             4043\n",
       "Oklahoma                4043\n",
       "Utah                    4043\n",
       "New Hampshire           4043\n",
       "Kentucky                4043\n",
       "Maryland                4043\n",
       "Rhode Island            4043\n",
       "Massachusetts           4043\n",
       "Michigan                4043\n",
       "New Jersey              4043\n",
       "Kansas                  4043\n",
       "South Dakota            4043\n",
       "Minnesota               4043\n",
       "Tennessee               4043\n",
       "New York                4043\n",
       "Washington              4043\n",
       "Louisiana               4043\n",
       "Montana                 4043\n",
       "North Dakota            4043\n",
       "Wisconsin               4043\n",
       "Nebraska                4043\n",
       "Vermont                 4043\n",
       "Nevada                  4043\n",
       "Maine                   4043\n",
       "North Carolina          4043\n",
       "West Virginia           4043\n",
       "Virginia                4043\n",
       "Oregon                  4043\n",
       "New Mexico              4043\n",
       "Texas                   4043\n",
       "Pennsylvania            4043\n",
       "Ohio                    4043\n",
       "South Carolina          4043\n",
       "Missouri                4043\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers['state'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d826d67-a59b-442d-81b0-f11361421c2f",
   "metadata": {},
   "source": [
    "**Comment** : This looks like it was artificially generated data. It's heavily unlikely that InstaCart database had the same (or almost the same) number of customers for all states!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e653b338-8910-42a2-a21b-73a5ac03ab26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Male      104067\n",
       "Female    102142\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers['gender'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1009cc99-542c-45db-88a7-bb9871381462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/1/2017'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers['date_joined'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d91d0547-1f46-4f08-a663-3decd34264f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9/9/2019'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers['date_joined'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49849736-2456-4557-9a3f-7ad4d5894d36",
   "metadata": {},
   "source": [
    "From other investigations, I know this max value is wrong, because at this stage, date_joined is an object, and it's being sorted like a string, providing a wrong value (there are dates in the year 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6af673-6b39-42d1-8747-0871fdfbf5b1",
   "metadata": {},
   "source": [
    "##### Memory saving handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e4d00aa-0b2c-4aa4-91ec-cebfb044c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory saving mitigation measures - reducing datatypes to the minimum possible according to the content of each field\n",
    "#For this dataframe is not much relevant, because it occupies only some MB, but later when merging with the orders df will be important\n",
    "\n",
    "df_customers['user_id']=df_customers['user_id'].astype('int32')\n",
    "df_customers['age']=df_customers['age'].astype('int8')\n",
    "df_customers['number_of_dependants']=df_customers['number_of_dependants'].astype('int8')\n",
    "df_customers['income']=df_customers['income'].astype('int32')\n",
    "\n",
    "#additionally, to be able to handle dates properly, I'm transforming date_joined field. \n",
    "#This doesn't save memory, but doesn't waste it as well\n",
    "df_customers['date_joined']=df_customers['date_joined'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efae0521-8166-4c79-a59a-0b71fcfa5adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   user_id               206209 non-null  int32         \n",
      " 1   gender                206209 non-null  object        \n",
      " 2   state                 206209 non-null  object        \n",
      " 3   age                   206209 non-null  int8          \n",
      " 4   date_joined           206209 non-null  datetime64[ns]\n",
      " 5   number_of_dependants  206209 non-null  int8          \n",
      " 6   family_status         206209 non-null  object        \n",
      " 7   income                206209 non-null  int32         \n",
      "dtypes: datetime64[ns](1), int32(2), int8(2), object(3)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76cf6718-6131-4bf5-a39d-24ab6726f7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-01 00:00:00')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers['date_joined'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a3907ff-809e-46fa-af17-ae67997b26c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-04-01 00:00:00')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers['date_joined'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2150e26-44dc-457e-8e96-5186d75979df",
   "metadata": {},
   "source": [
    "With the field `date_joined` effectively as `datetime64` type, and with the library `datetime` the results are now correct "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086dfa8-5b4c-4a5d-b215-a21aeb13ad4f",
   "metadata": {},
   "source": [
    "##### Additional investigation about outliers in income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a164b7-d66e-4165-b942-e7c46cb3cd25",
   "metadata": {},
   "source": [
    "By applying the rule Upper Outliers as $$Q75 + 1.5 * (Q75 - Q25) = 124244 + 1.5 * (124244 - 59874) = 220799$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31f155a-b34c-43e5-be8b-c90ce92bdc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>number_of_dependants</th>\n",
       "      <th>family_status</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>117740</td>\n",
       "      <td>Female</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>55</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>292759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>159362</td>\n",
       "      <td>Female</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>74</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>372334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>15683</td>\n",
       "      <td>Male</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>40</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>251211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>200930</td>\n",
       "      <td>Male</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>60</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>300913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>136298</td>\n",
       "      <td>Male</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>47</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>433206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204513</th>\n",
       "      <td>21667</td>\n",
       "      <td>Male</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>53</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>single</td>\n",
       "      <td>518856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204598</th>\n",
       "      <td>5839</td>\n",
       "      <td>Male</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>52</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>275506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205458</th>\n",
       "      <td>62924</td>\n",
       "      <td>Male</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>75</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>245958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206105</th>\n",
       "      <td>5519</td>\n",
       "      <td>Female</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>78</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>262610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206151</th>\n",
       "      <td>200065</td>\n",
       "      <td>Male</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>59</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>243617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  gender           state  age date_joined  \\\n",
       "34       117740  Female          Oregon   55  2017-01-01   \n",
       "434      159362  Female        Missouri   74  2017-01-03   \n",
       "818       15683    Male      New Mexico   40  2017-01-05   \n",
       "979      200930    Male  South Carolina   60  2017-01-06   \n",
       "991      136298    Male      New Mexico   47  2017-01-06   \n",
       "...         ...     ...             ...  ...         ...   \n",
       "204513    21667    Male       Tennessee   53  2020-03-22   \n",
       "204598     5839    Male      New Jersey   52  2020-03-23   \n",
       "205458    62924    Male  South Carolina   75  2020-03-28   \n",
       "206105     5519  Female         Georgia   78  2020-04-01   \n",
       "206151   200065    Male       Tennessee   59  2020-04-01   \n",
       "\n",
       "        number_of_dependants family_status  income  \n",
       "34                         1       married  292759  \n",
       "434                        3       married  372334  \n",
       "818                        1       married  251211  \n",
       "979                        1       married  300913  \n",
       "991                        3       married  433206  \n",
       "...                      ...           ...     ...  \n",
       "204513                     0        single  518856  \n",
       "204598                     3       married  275506  \n",
       "205458                     1       married  245958  \n",
       "206105                     3       married  262610  \n",
       "206151                     3       married  243617  \n",
       "\n",
       "[875 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.loc[df_customers['income'] >= 220799]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c1c10-9a05-4be6-984f-77974d4069ab",
   "metadata": {},
   "source": [
    "875 customers can be found beyond this limit. While they can be considered as top-top earners (they are approximately the 0.3% of highest incomes), I'll proceed with them in the study, because global consumption patterns might reveal something."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4867216-b8e2-42fc-ac4f-cbc846e73433",
   "metadata": {},
   "source": [
    "### Step 6 - Combine your customer data with the rest of your prepared Instacart data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4f3a7-fd04-4107-82cf-da5eab8287f9",
   "metadata": {},
   "source": [
    "Before proceeding here, it should be noted that I returned to this script to further clean up the dataframes I want to merge.\n",
    "\n",
    "When I arrived to the final task of the project, I've thoroughly listed the business questions I wanted to answer, checked which fields had the data for those answers, and came back to clean up the dataframes as much as I could, dropping all unnecessary fields.\n",
    "\n",
    "In a realistic scenario, I would probably not be facing the memory restrictions I'm facing in this challenge (would have a better computer), and would leave the fields in place to analyse further, if the stakeholders would wish so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f3fa72b-c37c-4693-866d-d58bc972175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up of the customers dataframe\n",
    "df_customers.drop(['gender','date_joined','family_status'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d7ee070-5b13-4997-a103-4faa93d6dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe of orders_products\n",
    "#to be noted here that the pickle file with a 70% random slice of the full orders_products dataset is being used here, \n",
    "#due to memory restrictions. This was done while walking through the exercise 4.9\n",
    "\n",
    "#options to load either the 70% slice or the full dataframe, keep commented the line that is not desired\n",
    "df_orders_products_merged = pd.read_pickle(os.path.join(data_path, '2_Prepared_Data', 'orders_products_sliced_70pc.pkl'))\n",
    "#df_orders_products_merged = pd.read_pickle(os.path.join(data_path, '2 Prepared Data', 'orders_products_labeled_v3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50bd4498-ea4d-4d28-b6f7-f88b1b66b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up of the orders_products dataframe\n",
    "\n",
    "df_orders_products_merged.drop(['busy','busy_days','busiest_period_of_day','product_name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be054757-d593-46af-9cea-243cbc1c1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#further optimization of other field datatypes\n",
    "\n",
    "df_orders_products_merged['department_id'] = df_orders_products_merged['department_id'].astype('int8')\n",
    "df_orders_products_merged['prices'] = df_orders_products_merged['prices'].astype('float32')\n",
    "df_orders_products_merged['median_days_between_orders'] = df_orders_products_merged['median_days_between_orders'].astype(pd.Float32Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b7ce326-3a22-47cd-bd01-98b4e3b77d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22682953 entries, 1 to 32403717\n",
      "Data columns (total 16 columns):\n",
      " #   Column                            Dtype  \n",
      "---  ------                            -----  \n",
      " 0   order_id                          int32  \n",
      " 1   user_id                           int32  \n",
      " 2   customer_sequential_order_number  int8   \n",
      " 3   orders_day_of_week                int8   \n",
      " 4   order_hour_of_day                 int8   \n",
      " 5   days_since_prior_order            Int8   \n",
      " 6   product_id                        int32  \n",
      " 7   department_id                     int8   \n",
      " 8   prices                            float32\n",
      " 9   price_range_loc                   int8   \n",
      " 10  max_order                         int8   \n",
      " 11  loyalty_flag                      int8   \n",
      " 12  avg_price_per_user                float64\n",
      " 13  high_spender_flag                 bool   \n",
      " 14  median_days_between_orders        Float32\n",
      " 15  frequency_flag                    int8   \n",
      "dtypes: Float32(1), Int8(1), bool(1), float32(1), float64(1), int32(3), int8(8)\n",
      "memory usage: 1.0 GB\n"
     ]
    }
   ],
   "source": [
    "df_orders_products_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d8513-b5f0-401d-bd48-7c435999118b",
   "metadata": {},
   "source": [
    "It's confirmed that `user_id` (the field that will be used to combine both dataframes) has the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a41112a-90dd-43d7-ba08-ab8cbd25b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the 70% slice with the customers\n",
    "df_ord_prod_cust = df_orders_products_merged.merge(df_customers, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83154180-5720-4182-8548-14625441b58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22682953, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check on how many records remain\n",
    "df_ord_prod_cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "946cf359-0f35-4516-a4e2-d23166803b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206195"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ord_prod_cust['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc732a2-c3e7-4025-923a-f02dd99a6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the resulting dataframe\n",
    "df_ord_prod_cust.to_pickle(os.path.join(data_path, '2_Prepared_Data', 'orders_products_customers.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d7fde-4bbb-49b5-b713-210b8f617004",
   "metadata": {},
   "source": [
    "### Alternative section\n",
    "\n",
    "In this section, there's a demonstration of how to attempt a variant of the plan B on memory to deal with the full dataframe.\n",
    "This attempt tries to do the merge in smaller chuncks, and store them step by step in the output .csv file\n",
    "\n",
    "The following algorithm was inspired in a solution from ChatGPT, with the prompt:\n",
    "\n",
    "*i have a big pandas dataframe in memory and want to merge it in smaller pieces with another dataframe, and then store those partial merges into a csv file. show me python code to do this.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0a023-1592-4671-a6b2-b805ec928cb5",
   "metadata": {},
   "source": [
    "The code below is all commented to avoid being run when running the full script. Take off comments on code lines, if you want to experiment.\n",
    "\n",
    "I tried in a machine of 8GB RAM total, around 2GB available, and it worked. Took more than 40 minutes, and generated a csv file with a total size of 22.7GB. Not useful, I'll proceed with the merge using the pickle file with 70% slice of the ordered items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa8bfcd0-77b3-43f8-a4e9-c7c3e09422e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chunk_size = 10000'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the chunk size\n",
    "# Adjustable based on available memory\n",
    "\n",
    "\"\"\"chunk_size = 10000\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc811d1d-5f8a-425b-874d-5060d906353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_rows = len(df_orders_products_merged)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an iterator over orders_products dataframe\n",
    "\n",
    "\"\"\"num_rows = len(df_orders_products_merged)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "667de1d7-451a-478d-af69-10503c7b00f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_result = pd.DataFrame(columns=(df_orders_products_merged.columns.append(df_customers.columns)).unique())\\ndf_result.to_csv(os.path.join(data_path, \\'2 Prepared Data\\', \"orders_products_customers.csv\"),index_label=False)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an empty dataframe just for the definition of the columns and write it to a new csv file\n",
    "\n",
    "\"\"\"\n",
    "df_result = pd.DataFrame(columns=(df_orders_products_merged.columns.append(df_customers.columns)).unique())\n",
    "df_result.to_csv(os.path.join(data_path, '2 Prepared Data', \"orders_products_customers.csv\"),index_label=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df610f03-8b09-43e3-be94-10b3d3ea6b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfor i in range(0, num_rows, chunk_size):\\n    # Get the chunk\\n    df_chunk = df_orders_products_merged.iloc[i:i+chunk_size]\\n\\n    # Perform the merge (adjust how=\"inner\"/\"outer\"/\"left\"/\"right\" as needed)\\n    df_merged_chunk = pd.merge(df_chunk, df_customers, on=\"user_id\", how=\"inner\")\\n\\n    # Write to CSV, appending after the first chunk\\n    df_merged_chunk.to_csv(os.path.join(data_path, \\'2 Prepared Data\\', \\'orders_products_customers.csv\\'), mode=\\'a\\', header=False, index=False)\\n\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "for i in range(0, num_rows, chunk_size):\n",
    "    # Get the chunk\n",
    "    df_chunk = df_orders_products_merged.iloc[i:i+chunk_size]\n",
    "\n",
    "    # Perform the merge (adjust how=\"inner\"/\"outer\"/\"left\"/\"right\" as needed)\n",
    "    df_merged_chunk = pd.merge(df_chunk, df_customers, on=\"user_id\", how=\"inner\")\n",
    "\n",
    "    # Write to CSV, appending after the first chunk\n",
    "    df_merged_chunk.to_csv(os.path.join(data_path, '2 Prepared Data', 'orders_products_customers.csv'), mode='a', header=False, index=False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ec274-a1cb-4af0-bb86-1d11ffd02875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
